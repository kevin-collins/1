{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch学习.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxRL1f3sgi2s"
      },
      "source": [
        "# **Pytorch Note**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6JQ3-WUggag"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmMgnph9hEfb"
      },
      "source": [
        "构建随机未初始化的矩阵 size为5*3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hst4fsEJg0Yr",
        "outputId": "6e5aecac-41c9-48bb-f855-52bc254a7d19"
      },
      "source": [
        "x = torch.empty(5,3)\n",
        "x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.9580e-33,  3.0822e-41,  3.3631e-44],\n",
              "        [ 0.0000e+00,         nan,  0.0000e+00],\n",
              "        [ 4.4721e+21,  1.5956e+25,  4.7399e+16],\n",
              "        [ 3.7293e-08,  1.4838e-41,  0.0000e+00],\n",
              "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uvEpWWHje08"
      },
      "source": [
        "在0-1随机初始化矩阵"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7P8ZosOjhTH",
        "outputId": "288e81dd-5044-4bac-dc96-53a277144b66"
      },
      "source": [
        "x = torch.rand(5,3)\n",
        "x"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7348, 0.1253, 0.7434],\n",
              "        [0.1478, 0.0506, 0.2457],\n",
              "        [0.6034, 0.5065, 0.4468],\n",
              "        [0.0773, 0.0470, 0.1988],\n",
              "        [0.5263, 0.9421, 0.1840]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FsI2vi2hOA7"
      },
      "source": [
        "构建一个全部为0 类型为long的矩阵"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOTfSw4MhSVT",
        "outputId": "0bb460a1-7b6e-4ee7-c9c7-371bfdc104a1"
      },
      "source": [
        "x = torch.zeros(5,3,dtype=torch.long)\n",
        "x\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EULzauchzkZ"
      },
      "source": [
        "从数据直接构建tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ0zru1lh3rj",
        "outputId": "f8bd3e0c-ea16-4108-dbf9-1c533ae2eefc"
      },
      "source": [
        "x = torch.tensor([5,5,3])\n",
        "x"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 5, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4yupq2qiFRx"
      },
      "source": [
        "利用原有tensor构建新tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhF_Qq7kiKhZ",
        "outputId": "b893f50f-1e92-413c-dd5f-8c5e557851c0"
      },
      "source": [
        "x = x.new_ones(5,3)\n",
        "x"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8c73qQ4j2K4"
      },
      "source": [
        "得到形状相同的tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HAeOc6HiW76",
        "outputId": "d642bd23-799e-4a89-9b09-3a4504d0f2b5"
      },
      "source": [
        "x = torch.randn_like(x,dtype=torch.float)\n",
        "x"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8279, -0.2552,  0.9544],\n",
              "        [-0.0385,  0.5376, -0.5223],\n",
              "        [-1.4302, -1.2234, -1.1382],\n",
              "        [ 0.7680,  0.1852, -0.6463],\n",
              "        [-0.2558, -1.1903,  1.0131]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR31kO9litkx"
      },
      "source": [
        "获得tensor的size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URSTp6Wviwvk",
        "outputId": "6ecbdeba-9f51-4226-a96c-5662b157a074"
      },
      "source": [
        "x.size()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkn5AWqVi5Tb"
      },
      "source": [
        "**Operation介绍**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnf3bioDi9tZ"
      },
      "source": [
        "加法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjK4UzHQi_qE",
        "outputId": "c987ba34-5ba7-401c-a5fa-3751784e2413"
      },
      "source": [
        "x = torch.rand(5,3)\n",
        "y = torch.rand(5,3)\n",
        "x\n",
        "y"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.8947e-01, 7.5013e-01, 8.1698e-01],\n",
              "        [6.9753e-01, 5.8730e-01, 3.1334e-04],\n",
              "        [9.1243e-02, 5.0363e-01, 7.7099e-01],\n",
              "        [5.8149e-01, 9.4084e-03, 9.1270e-01],\n",
              "        [4.2103e-01, 6.2405e-01, 4.8425e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ_S_NtqkLUC",
        "outputId": "bc0db214-4a01-403b-8736-b3d358b4e33c"
      },
      "source": [
        "x + y"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6305, 1.0551, 1.6968],\n",
              "        [1.0692, 1.5418, 0.9777],\n",
              "        [0.7846, 1.2300, 1.0307],\n",
              "        [1.4538, 0.0449, 1.2372],\n",
              "        [1.4084, 1.2771, 1.4291]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cIHvdckkRUj",
        "outputId": "2d384e65-8832-4bba-8a62-a684629542f5"
      },
      "source": [
        "torch.add(x,y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6305, 1.0551, 1.6968],\n",
              "        [1.0692, 1.5418, 0.9777],\n",
              "        [0.7846, 1.2300, 1.0307],\n",
              "        [1.4538, 0.0449, 1.2372],\n",
              "        [1.4084, 1.2771, 1.4291]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAqzv-9FkhVz",
        "outputId": "cfe4ad73-91c6-4ffa-e2db-216076b42815"
      },
      "source": [
        "result = torch.empty(5,3)\n",
        "torch.add(x,y,out=result)\n",
        "result"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6305, 1.0551, 1.6968],\n",
              "        [1.0692, 1.5418, 0.9777],\n",
              "        [0.7846, 1.2300, 1.0307],\n",
              "        [1.4538, 0.0449, 1.2372],\n",
              "        [1.4084, 1.2771, 1.4291]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq6KVSs1ks4W"
      },
      "source": [
        "in-place加法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B98q_GfjkvnZ",
        "outputId": "cfb1f693-29fc-49cb-e2a7-c8867cf327e1"
      },
      "source": [
        "y.add_(x)\n",
        "y"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6305, 1.0551, 1.6968],\n",
              "        [1.0692, 1.5418, 0.9777],\n",
              "        [0.7846, 1.2300, 1.0307],\n",
              "        [1.4538, 0.0449, 1.2372],\n",
              "        [1.4084, 1.2771, 1.4291]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1uWBi0mk_vR"
      },
      "source": [
        "任何in-place的运算都会以 _ 结尾"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdHpTS4plNJA"
      },
      "source": [
        "如果希望resize一个tensor 可以使用torch.view:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-L57LXilVGM",
        "outputId": "6aac2843-3c3e-4ed9-d0ff-da017300f672"
      },
      "source": [
        "x = torch.rand(4,4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1,8)  #使用一个-1 可以自动计算其应该是什么值 如此时应该是2*8\n",
        "z"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0885, 0.5177, 0.5828, 0.6383, 0.7980, 0.8906, 0.1653, 0.4193],\n",
              "        [0.8483, 0.6918, 0.0247, 0.5177, 0.3395, 0.3442, 0.4719, 0.1178]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqP6cIz_lvM6"
      },
      "source": [
        "如果只有一个元素的tensor 可以使用item()转化成python元素"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ3x6Cpal8as",
        "outputId": "9ad64d6a-ba5b-4e5d-facf-63cc22ae855c"
      },
      "source": [
        "x = torch.rand(1)\n",
        "x.item()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09365296363830566"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPbcqi0qmrtD"
      },
      "source": [
        "**CUDA Tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMCO7tFAmuQ3"
      },
      "source": [
        "使用.to方法 tensor可以被移动到别的device上"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stpd68rpmz8g"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cude\")\n",
        "  y = torch.ones_like(x,device=device)\n",
        "  x = x.to(device)\n",
        "  z = x + y\n",
        "  z.to(\"cpu\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHVH3p9Mns10"
      },
      "source": [
        "model = model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAblKWsIndfE"
      },
      "source": [
        "# **用numpy实现两层神经网络**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aFSWbYHnjdr"
      },
      "source": [
        "一个全连接Relu神经网络，一个隐藏层，没有bias，用x预测y，使用L2 loss\n",
        "\n",
        "h = W1 * X\n",
        "a = max(0, h) #relu\n",
        "y_pred = W2 * a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhNanEIjrFgG"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh2woI7hqusb"
      },
      "source": [
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# 随机创建训练数据\n",
        "x = np.random.randn(N, D_in)\n",
        "y = np.random.randn(N, D_out)\n",
        "\n",
        "w1 = np.random.randn(D_in, H)\n",
        "w2 = np.random.randn(H, D_out)\n",
        "\n",
        "LR = 1e-6\n",
        "\n",
        "for it in range(500):\n",
        "  # Forward\n",
        "  h = x.dot(w1) #[N * D_in] * [D_in * H] = [N * H]\n",
        "  h_relu = np.maximum(h, 0) # relu([N * H])\n",
        "  y_pred = h_relu.dot(w2) # [N * H] * [H * D_out] = [N * D_out]\n",
        "\n",
        "  # compute loss\n",
        "  loss = np.square(y_pred - y).sum() #均方误差 L2\n",
        "  print(it, loss)\n",
        "\n",
        "  # Backward \n",
        "  # compute the gradient 链式求导 d(loss)/d(w)\n",
        "  grad_y_pred = 2.0 * (y_pred - y) # d(loss)/d(y_pred) {loss = (y_pred-y)2}求导\n",
        "  grad_w2 = h_relu.T.dot(grad_y_pred)\n",
        "  \n",
        "  grad_h_relu = grad_y_pred.dot(w2.T)\n",
        "  grad_h = grad_h_relu.copy()\n",
        "  grad_h[h<0] = 0\n",
        "  grad_w1 = x.T.dot(grad_h)\n",
        "\n",
        "  # update w \n",
        "  w1 -= LR * grad_w1\n",
        "  w2 -= LR * grad_w2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP-zlrKaxEm5"
      },
      "source": [
        "# **使用pytorch进行训练**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCTrFpMC1a-K"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nsotx_exJAT"
      },
      "source": [
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# 随机创建训练数据\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "w1 = torch.randn(D_in, H, requires_grad=True)\n",
        "w2 = torch.randn(H, D_out, requires_grad=True)\n",
        "\n",
        "LR = 1e-6\n",
        "for it in range(500):\n",
        "  # Forward\n",
        "  y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
        "\n",
        "  # compute loss\n",
        "  loss = (y_pred - y).pow(2).sum() #均方误差 L2\n",
        "  print(it, loss.item())\n",
        "\n",
        "  # Backward \n",
        "  # compute the gradient 链式求导 d(loss)/d(w)\n",
        "  loss.backward()\n",
        "\n",
        "  # update w \n",
        "  with torch.no_grad(): # 不记住w1.grad和w2.grad\n",
        "    w1 -= LR * w1.grad\n",
        "    w2 -= LR * w2.grad\n",
        "    w1.grad.zero_() #手动置0 防止grad叠加\n",
        "    w2.grad.zero_()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXZxOgKqyASd"
      },
      "source": [
        "**简单的autograd**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAM16P_OyDns",
        "outputId": "b6758594-25b9-4ee3-8a19-bfd9ca57c934"
      },
      "source": [
        "x = torch.tensor(1., requires_grad=True)\n",
        "w = torch.tensor(2., requires_grad=True)\n",
        "b = torch.tensor(3., requires_grad=True)\n",
        "\n",
        "y = w * x + b\n",
        "\n",
        "y.backward()\n",
        "\n",
        "#dy / dw\n",
        "print(w.grad)\n",
        "print(x.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.)\n",
            "tensor(2.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VnSfF_S3CcR"
      },
      "source": [
        "**pytorch:nn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS99ZQVa3MAO"
      },
      "source": [
        "import torch.nn as nn\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# 随机创建训练数据\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H, bias=False), # w1*x+b bias可以设置为false\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "\n",
        "#model = model.to(\"cuda\")\n",
        "torch.nn.init.normal_(model[0].weight) #权重初始化为正态分布\n",
        "torch.nn.init.normal_(model[2].weight)\n",
        "\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction='sum')\n",
        "\n",
        "LR = 1e-6\n",
        "\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "for it in range(500):\n",
        "  # Forward\n",
        "  y_pred = model(x)\n",
        "\n",
        "  # compute loss\n",
        "  loss = loss_fn(y_pred, y) #均方误差 L2\n",
        "  print(it, loss.item())\n",
        "\n",
        "  # Backward \n",
        "  # compute the gradient 链式求导 d(loss)/d(w)\n",
        "  loss.backward()\n",
        "\n",
        "  # update w \n",
        "  with torch.no_grad(): # 不记住w1.grad和w2.grad\n",
        "    for param in model.parameters():\n",
        "      param -= LR * param.grad\n",
        "  \n",
        "  model.zero_grad()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR4Cz19o90Qp"
      },
      "source": [
        "引入了optimizer来计算权值"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZvgLNqP6fkH"
      },
      "source": [
        "import torch.nn as nn\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# 随机创建训练数据\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H, bias=False), # w1*x+b bias可以设置为false\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "\n",
        "#model = model.to(\"cuda\")\n",
        "#torch.nn.init.normal_(model[0].weight) #权重初始化为正态分布\n",
        "#torch.nn.init.normal_(model[2].weight)\n",
        "\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction='sum')\n",
        "\n",
        "LR = 1e-6\n",
        "\n",
        "# 使用optimizer来进行权重优化 可以选用不同的算法Adam SGD等\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "for it in range(500):\n",
        "  # Forward\n",
        "  y_pred = model(x)\n",
        "\n",
        "  # compute loss\n",
        "  loss = loss_fn(y_pred, y) #均方误差 L2\n",
        "  print(it, loss.item())\n",
        "\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  # Backward \n",
        "  # compute the gradient 链式求导 d(loss)/d(w)\n",
        "  loss.backward()\n",
        "\n",
        "  # update optimizer\n",
        "  optimizer.step() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiJzRoay9s_s"
      },
      "source": [
        "使用class来定义网络结构 （实践使用类型）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gniXFi907WVV"
      },
      "source": [
        "import torch.nn as nn\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# 随机创建训练数据\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "class TwoLayerNet(torch.nn.Module):\n",
        "  def __init__(self, D_in, D_out):\n",
        "    super(TwoLayerNet, self).__init__()\n",
        "    #定义结构\n",
        "    self.Linear1 = torch.nn.Linear(D_in, H, bias=False)\n",
        "    self.Linear2 = torch.nn.Linear(H, D_out)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_pred = self.Linear2(self.Linear1(x).clamp(min=0))\n",
        "    return y_pred\n",
        "\n",
        "model = TwoLayerNet(D_in, D_out)\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction='sum')\n",
        "\n",
        "LR = 1e-4\n",
        "\n",
        "# 使用optimizer来进行权重优化 可以选用不同的算法Adam SGD等\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "for it in range(500):\n",
        "  # Forward\n",
        "  y_pred = model(x)\n",
        "\n",
        "  # compute loss\n",
        "  loss = loss_fn(y_pred, y) #均方误差 L2\n",
        "  print(it, loss.item())\n",
        "\n",
        "\n",
        "  optimizer.zero_grad() #清空梯度\n",
        "  # Backward \n",
        "  # compute the gradient 链式求导 d(loss)/d(w)\n",
        "  loss.backward()\n",
        "\n",
        "  # update optimizer\n",
        "  optimizer.step() "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}